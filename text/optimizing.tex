\section{Оптимизации и улучшения производительности}

\subsection{Профилирование и выявление узких мест}

Для анализа производительности сборщика мусора в процессе прохождения бенчмарков был использован инструмент низкоуровневого профилирования — \textbf{Perforator}, который позволяет визуализировать вызовы функций в виде флеймграфа (flamegraph). Данный подход позволил локализовать ключевые узкие места в работе GC.

Главным боттлнеком оказалась функция \texttt{FindAllocation} — она отвечает за поиск объекта в множестве аллокаций по произвольному указателю. Эта операция выполняется многократно в процессе маркировки (\texttt{MarkRoots}, \texttt{MarkHeapAllocs}) и критична к производительности.

\subsection{Проблема точного поиска}

Первоначально для хранения аллокаций использовалась структура \texttt{std::map}, предоставляющая логарифмическое время доступа. Однако классический поиск по ключу невозможен в данной задаче: пользовательский указатель может указывать не на начало объекта, а на произвольную внутреннюю часть (например, после \texttt{ptr + k}). Таким образом, GC должен искать вхождение по диапазону: найти такую аллокацию, что \texttt{alloc.ptr <= ptr < alloc.ptr + alloc.size}.

В силу этого нельзя было использовать хеш-таблицу, а \texttt{std::map} оказалась узким местом по времени и кэш-локальности.

\subsection{Переход на вектор с сортировкой}

Была реализована следующая замена:

\begin{itemize}
    \item Вместо \texttt{std::map} используется \texttt{std::vector<Allocation>},\\ в котором перед каждой сборкой аллокации сортируются по \texttt{ptr}.
    \item Для поиска применяется бинарный поиск с модификацией: после нахождения ближайшей левой границы проверяется, входит ли указатель внутрь диапазона аллокации.
\end{itemize}

Несмотря на одинаковую асимптотику поиска (\(O(\log n)\)), на практике такой подход дал более чем \textbf{двухкратное ускорение} только этой функции за счёт лучшей кэш-локальности и компактного представления. Также ускорились все остальные стадии сборки мусора и функции GC, так как операции с \texttt{std::vector} намного быстрее, чем с std::map.

\subsection{Эвристики для ускорения поиска}

Для ускорения \texttt{FindAllocation} были реализованы две эвристики:

\paragraph{Фильтрация по heap-диапазону}

Поскольку корневые области (\texttt{GCRoots}) часто представляют собой стек или неинициализированную память, они содержат множество произвольных значений, не являющихся валидными указателями. Эти значения, как правило, значительно меньше чем адреса в heap.

Была добавлена предварительная проверка: если значение указателя явно вне диапазона heap, поиск не запускается. Такая оптимизация уменьшает количество ложных вызовов \texttt{FindAllocation}.

\paragraph{Кэширование последнего результата поиска}

Вторая эвристика основывается на том, что при обходе памяти множество указателей имеют пространственную локальность. Поэтому вводится поле \texttt{prev\_find\_}, которое запоминает последнюю успешную аллокацию и позволяет ускорить следующий поиск, если он попадает в тот же диапазон. Такой подход дал дополнительное \textbf{двукратное ускорение} поиска.

\subsection{Оптимизация сортировки аллокаций}

После ускорения поиска стало очевидно, что значительное время начала занимать операция \texttt{SortAllocations}, выполняемая перед каждой сборкой. Изначально сортировка выполнялась полностью каждый раз, что имело сложность \(O(n \log n)\).

Реализована следующая схема:

\begin{itemize}
    \item Поддерживается индекс \texttt{last\_size\_}, указывающий, до какого места вектор уже отсортирован.
    \item Новые аллокации добавляются в конец вектора, и сортируется только эта часть.
    \item Затем применяется алгоритм \textbf{in-place merge} из сортировки слиянием, объединяющий отсортированные части в один массив за \(O(n)\).
\end{itemize}

Такой подход дал \textbf{троекратное ускорение} операции сортировки на больших объёмах.

\subsection{Итоговый эффект}

Оптимизации привели к следующим результатам:
\begin{itemize}
    \item \texttt{FindAllocation()} ускорена в 6 раз по сравнению с исходной реализацией на \texttt{std::map}. Тогда как общая производительность возросла почти в 10 раз.
    \item Общая фаза \texttt{Mark} стала занимать существенно меньше времени, особенно при большом количестве указателей.
    \item Время \texttt{Collect} стабилизировалось и стало менее чувствительно к росту числа аллокаций.
    \item Все изменения были протестированы и подтверждены на реальных бенчмарках (см. таблицы~\ref{table:drop_probability}, \ref{table:auto_gc}).
\end{itemize}

Эти улучшения обеспечили масштабируемость системы и подготовили основу для будущих расширений.
